{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "trabalho-1.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/italloalexsander/LeNet-Keras-Colab/blob/master/trabalho_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AeZFCiveBx1n",
        "colab_type": "text"
      },
      "source": [
        "Primeiro trabalho da disciplina\n",
        "\n",
        "Nome: Itallo Alexsander da Fonseca Ribeiro\n",
        "\n",
        "Especificação:\n",
        "\n",
        "Desenvolver a LeNet5, e realizar testes empíricos sobre o banco MNist (http://yann.lecun.com/exdb/mnist/), avaliando alterações:\n",
        "\n",
        "1. No tamanho dos filtros\n",
        "\n",
        "2. No número de filtros por camada\n",
        "\n",
        "3. No tamanho do batch\n",
        "\n",
        "4. Na taxa de aprendizagem\n",
        "\n",
        "5. No aumento de dados\n",
        "\n",
        "6. Nas funções de ativação e na inicialização dos pesos, testando as quatro combinações de Leak ReLU ou tanh x inicialização de Glorot ou de He. \n",
        "\n",
        "Data de entrega: 01/08\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gp5tGv8HBuBT",
        "colab_type": "code",
        "outputId": "2ce97972-eec1-40cb-c2a5-5178776a0fd1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 478
        }
      },
      "source": [
        "!pip install tensorflow-gpu"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow-gpu\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/76/04/43153bfdfcf6c9a4c38ecdb971ca9a75b9a791bb69a764d652c359aca504/tensorflow_gpu-1.14.0-cp36-cp36m-manylinux1_x86_64.whl (377.0MB)\n",
            "\u001b[K     |████████████████████████████████| 377.0MB 59kB/s \n",
            "\u001b[?25hRequirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.1.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.16.4)\n",
            "Requirement already satisfied: tensorboard<1.15.0,>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.14.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.1.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.11.2)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.33.4)\n",
            "Requirement already satisfied: tensorflow-estimator<1.15.0rc0,>=1.14.0rc0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.14.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.0.8)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.12.0)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.2.2)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.7.1)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.8.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.1.7)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.15.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (3.7.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow-gpu) (3.1.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow-gpu) (0.15.5)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow-gpu) (41.0.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow-gpu) (2.8.0)\n",
            "Installing collected packages: tensorflow-gpu\n",
            "Successfully installed tensorflow-gpu-1.14.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MCk1r1wMDhVi",
        "colab_type": "code",
        "outputId": "c5fd30a2-f0f1-48eb-dd05-3d4dbe6a2eab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 935
        }
      },
      "source": [
        "from keras.datasets import fashion_mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "tamBatch = 256\n",
        "numEpocas = 10\n",
        "\n",
        "imgX, imgY = 28, 28\n",
        "numClasses = 10 \n",
        "\n",
        "(x_train, y_train), (x_val, y_val) = fashion_mnist.load_data()\n",
        "x_train = x_train.reshape(x_train.shape[0], imgX, imgY, 1)\n",
        "x_val = x_val.reshape(x_val.shape[0], imgX, imgY, 1)\n",
        "\n",
        "input_format = (imgX, imgY, 1)\n",
        "\n",
        "x_train = x_train.astype('float32')\n",
        "x_val = x_val.astype('float32')\n",
        "\n",
        "x_train /= 255\n",
        "x_val /= 255\n",
        "\n",
        "y_train = to_categorical(y_train, numClasses)\n",
        "y_val = to_categorical(y_val, numClasses)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(filters=6, kernel_size=(5,5), activation='relu', input_shape=input_format))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Conv2D(filters=16, kernel_size=(5,5), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Conv2D(filters=120, kernel_size=(3,3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(120, activation='relu'))\n",
        "model.add(Dense(84, activation='relu'))\n",
        "model.add(Dense(numClasses, activation='softmax'))\n",
        "model.summary()\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adadelta', metrics=['accuracy'])\n",
        "model.fit(x_train, y_train, batch_size=tamBatch, validation_data=(x_val, y_val), verbose = 1, epochs = numEpocas)\n",
        "score = model.evaluate(x_val, y_val, verbose=0)\n",
        "print('Valor de perda: ', score[0])\n",
        "print('Valor de acurácia: ', score[1])\n",
        "\n",
        "\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_31 (Conv2D)           (None, 24, 24, 6)         156       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_31 (MaxPooling (None, 12, 12, 6)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_32 (Conv2D)           (None, 8, 8, 16)          2416      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_32 (MaxPooling (None, 4, 4, 16)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_33 (Conv2D)           (None, 2, 2, 120)         17400     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_33 (MaxPooling (None, 1, 1, 120)         0         \n",
            "_________________________________________________________________\n",
            "flatten_12 (Flatten)         (None, 120)               0         \n",
            "_________________________________________________________________\n",
            "dense_27 (Dense)             (None, 120)               14520     \n",
            "_________________________________________________________________\n",
            "dense_28 (Dense)             (None, 84)                10164     \n",
            "_________________________________________________________________\n",
            "dense_29 (Dense)             (None, 10)                850       \n",
            "=================================================================\n",
            "Total params: 45,506\n",
            "Trainable params: 45,506\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 4s 69us/step - loss: 1.0232 - acc: 0.6118 - val_loss: 0.6659 - val_acc: 0.7339\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.5489 - acc: 0.7935 - val_loss: 0.5157 - val_acc: 0.8162\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 3s 55us/step - loss: 0.4541 - acc: 0.8321 - val_loss: 0.4553 - val_acc: 0.8384\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.4038 - acc: 0.8515 - val_loss: 0.4125 - val_acc: 0.8521\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.3701 - acc: 0.8638 - val_loss: 0.3740 - val_acc: 0.8624\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 3s 55us/step - loss: 0.3458 - acc: 0.8728 - val_loss: 0.4211 - val_acc: 0.8557\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 3s 55us/step - loss: 0.3283 - acc: 0.8785 - val_loss: 0.3980 - val_acc: 0.8545\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.3132 - acc: 0.8831 - val_loss: 0.3495 - val_acc: 0.8715\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 3s 55us/step - loss: 0.3043 - acc: 0.8863 - val_loss: 0.3607 - val_acc: 0.8680\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 3s 55us/step - loss: 0.2927 - acc: 0.8909 - val_loss: 0.4024 - val_acc: 0.8466\n",
            "Valor de perda:  0.40242076075077055\n",
            "Valor de acurácia:  0.8466\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xMhHmDtpLMc-",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    }
  ]
}